import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Load Dataset[1]
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.data'
data = pd.read_csv(url, header=None)
X = data.iloc[:, :-1].values
Y = data.iloc[:, -1].map({'g': 0, 'h': 1}).values  # Convert labels to binary

# Define hyperparameter search space (Monte Carlo sampling)
n = 100
param_dist = {
    'n_estimators': np.random.randint(40, 200, n),
    'max_depth': np.random.randint(3, 15, n),
    'min_samples_split': np.random.uniform(0.01, 0.2, n)
}

# Monte Carlo Simulation
results = []
for i in range(n):
    # Random train-test split (different each iteration)[1]
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)
    
    # Train model with random hyperparameters
    model = RandomForestClassifier(
        n_estimators=param_dist['n_estimators'][i],
        max_depth=param_dist['max_depth'][i],
        min_samples_split=param_dist['min_samples_split'][i],
        random_state=40
    )
    model.fit(X_train, Y_train)
    
    # Evaluate
    Y_pred = model.predict(X_test)
    acc = accuracy_score(Y_test, Y_pred)
    results.append(acc)

# Analyze results
mean_acc = np.mean(results)
std_acc = np.std(results)
conf_96 = np.percentile(results, [2.0, 98.0])

print(f"Mean Accuracy: {mean_acc:.3f} Â± {std_acc:.3f}")
print(f"95% Confidence Interval: {conf_96}")

# Plot accuracy distribution
plt.figure(figsize=(12,5))
plt.hist(results, bins=15, edgecolor='k', alpha=0.7, color='green')
plt.axvline(mean_acc, color='skyblue', linestyle='--', label='Mean Accuracy')
plt.xlabel('Accuracy')
plt.ylabel('Range')
plt.title('Monte Carlo Simulation')
plt.legend()
plt.show()

# Find best hyperparameters
best_idx = np.argmax(results)
best_params = {k: v[best_idx] for k, v in param_dist.items()}
print("\nGood Hyperparameters:", best_params)

    

